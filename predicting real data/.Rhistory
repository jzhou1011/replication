if (results.data$s1[i]< 0 && results.data$s2[i]<(-z_score_nom))
results.data$actual_rep[i] = 1
}
#probability of s2 replicating given s1
calculate_pcondtional<-function(s1,sampleS1, sampleS2){
sd_S1<-sqrt(sampleS1*sigma^2+1)
sd_S2<-sqrt(sampleS2*sigma^2+1)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-1+((sampleS2*sigma^2)/(sd_S1)^2)
p <- s1
for (i in 1:NROW(s1)){
if (s1[i]>0){
#p[i]<-(1-mean(pnorm(z_score, mean[i], sqrt(var2))))
p[i]<-(1-pnorm(z_score, mean[i], sqrt(var2)))
}
else{
# p[i]<-mean(pnorm(-z_score, mean[i], sqrt(var2)))
p[i]<-pnorm(-z_score, mean[i], sqrt(var2))
}
}
return(p)
}
calculate_upperCI<-function(s1,sampleS1, sampleS2){
sd_S1<-sqrt(sampleS1*sigma^2+1)
sd_S2<-sqrt(sampleS2*sigma^2+1)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-1+((sampleS2*sigma^2)/(sd_S1)^2)
error <- qnorm(0.975)*sqrt(var2)
mean+error
}
calculate_lowerCI<-function(s1,sampleS1, sampleS2){
sd_S1<-sqrt(sampleS1*sigma^2+1)
sd_S2<-sqrt(sampleS2*sigma^2+1)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-1+((sampleS2*sigma^2)/(sd_S1)^2)
error <- qnorm(0.975)*sqrt(var2)
return(mean-error)
}
calculate_mean<-function(s1,sampleS1,sampleS2){
sd_S1<-sqrt(sampleS1*sigma^2+1)
sd_S2<-sqrt(sampleS2*sigma^2+1)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
}
pred_obs<-ggplot(data = results.data, mapping = aes(x = s1, y = s2)) +
geom_point()+
stat_function(fun=calculate_lowerCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2), color="paleturquoise2")+
stat_function(fun=calculate_upperCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2), color="paleturquoise2")+
stat_function(fun=calculate_mean, args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2), color="palevioletred1")
pred_obs
#testing on datasets from article
#reading in libraries
library(tidyverse)
library(MASS)
library(ggplot2)
library(dplyr)
library(plyr)
library(reshape2)
#read in file
#filename<-"./files/1_19820697_data_upbuilt_filtered_upbuilt.csv" #straight+too few data
#filename<-"./files/2_19820697_data_upbuilt_filtered_upbuilt.csv" #straight+too few data
#filename<-"./files/3_19820697_data_upbuilt_filtered_upbuilt.csv" #not enough sig s2
#filename<-"./files/4_19820697_data_upbuilt_filtered_upbuilt.csv" #average #5 vs 12.96
#filename<-"./files/5_19820697_data_upbuilt_filtered_upbuilt.csv" #all sig #3 vs 2.997
filename<-"./files/1_19343178_data_upbuilt_filtered_upbuilt.csv" #good #6 vs 21.16
#filename<-"./files/1_25282103_data_upbuilt_filtered_upbuilt.csv" #good #6 vs 21.16
#args = commandArgs(trailingOnly=TRUE)
#filename<-args[1]
data<-read.csv(filename, sep=",")
#find test statsitic
results.data<-data.frame(data$beta.disc, data$se.disc)
results.data$s1<-(data$beta.disc)/(data$se.disc)
results.data$s2<-(data$beta.rep)/(data$se.rep)
#needed functions and math
M=nrow(data)
#var=2
var=data$trait.var[1]
#sampleSize
sigma=sqrt(var)
threshold=data$p.thresh[1]
z_score_nom <- qnorm(0.05,lower.tail = FALSE)
z_score <- qnorm(0.05/M,lower.tail =FALSE)
# sampleSizeS1=data$n.disc
# sampleSizeS2=data$n.rep
sampleSizeS1<-mean(data$n.disc)
sampleSizeS2<-mean(data$n.rep)
results.data$actual_rep = rep(0,M)
for (i in 1:M){
# if (results.data$s2[i]>z_score | results.data$s2[i]<(-z_score))
#   results.data$actual_rep[i] = 1
if (results.data$s2[i]>z_score_nom && results.data$s1[i]>0)
results.data$actual_rep[i] = 1
if (results.data$s1[i]< 0 && results.data$s2[i]<(-z_score_nom))
results.data$actual_rep[i] = 1
}
#probability of s2 replicating given s1
calculate_pcondtional<-function(s1,sampleS1, sampleS2){
sd_S1<-sqrt(sampleS1*sigma^2+1)
sd_S2<-sqrt(sampleS2*sigma^2+1)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-1+((sampleS2*sigma^2)/(sd_S1)^2)
p <- s1
for (i in 1:NROW(s1)){
if (s1[i]>0){
#p[i]<-(1-mean(pnorm(z_score, mean[i], sqrt(var2))))
p[i]<-(1-pnorm(z_score, mean[i], sqrt(var2)))
}
else{
# p[i]<-mean(pnorm(-z_score, mean[i], sqrt(var2)))
p[i]<-pnorm(-z_score, mean[i], sqrt(var2))
}
}
return(p)
}
calculate_upperCI<-function(s1,sampleS1, sampleS2){
sd_S1<-sqrt(sampleS1*sigma^2+1)
sd_S2<-sqrt(sampleS2*sigma^2+1)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-1+((sampleS2*sigma^2)/(sd_S1)^2)
error <- qnorm(0.975)*sqrt(var2)
mean+error
}
calculate_lowerCI<-function(s1,sampleS1, sampleS2){
sd_S1<-sqrt(sampleS1*sigma^2+1)
sd_S2<-sqrt(sampleS2*sigma^2+1)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-1+((sampleS2*sigma^2)/(sd_S1)^2)
error <- qnorm(0.975)*sqrt(var2)
return(mean-error)
}
calculate_mean<-function(s1,sampleS1,sampleS2){
sd_S1<-sqrt(sampleS1*sigma^2+1)
sd_S2<-sqrt(sampleS2*sigma^2+1)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
}
pred_obs<-ggplot(data = results.data, mapping = aes(x = s1, y = s2)) +
geom_point()+
stat_function(fun=calculate_lowerCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2), color="paleturquoise2")+
stat_function(fun=calculate_upperCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2), color="paleturquoise2")+
stat_function(fun=calculate_mean, args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2), color="palevioletred1")
pred_obs
#simulating data with confounding
#attempting to estimate the confouding with only the signifcant values
# #libraries
# library(tidyverse)
# library(MASS)
# library(ggplot2)
# library(dplyr)
# library(plyr)
# library(reshape2)
#simulating data
var_g<-0.82
var_c1<-10.0
var_c2<-2.0
sigma_g<-sqrt(var_g)
sigma_c1<-sqrt(var_c1) #first study
sigma_c2<-sqrt(var_c2) #second study
M<-32#number of snps
#pValue<-0.05/M
pValue<-(1*10^(-4))
ZScore<- qnorm(0.05/M,lower.tail =FALSE)
#ZScore<-5.2
#generating lambda
lambda <- rnorm(n=M, mean=0, sd=sigma_g)
#generating C1
delta1 <- rnorm(n=M, mean=0, sd=sigma_c1)
#simulating C2
delta2 <- rnorm(n=M, mean=0, sd=sigma_c2)
#generating two test statistics with different confounders
data1<-matrix(nrow=M, ncol=5)
for(i in 1:M){
data1[i,1]<-lambda[i]
data1[i,2]<-delta1[i]
data1[i,3]<-delta2[i]
data1[i,4]<-rnorm(n=1, mean=lambda[i]+delta1[i], sd=1) #s1
data1[i,5]<-rnorm(n=1, mean=lambda[i]+delta2[i], sd=1) #s2
}
data1=as.data.frame(data1)
colnames(data1)=c("lambda", "delta1", "delta2", "s1", "s2")
data1$avg<-(data1$s1+data1$s2)*0.5
s1SigData<-filter(data1, s1>ZScore | s1<(-ZScore))
s1s2<-ggplot(data=data1, mapping = aes(x=s1, y=s2))+geom_point()+
scale_y_continuous(breaks=seq(-8, 8, 1), limits=c(-8,8))+scale_x_continuous(breaks=seq(-8, 8, 1), limits=c(-8, 8))
#s1s2
s1Sigs2<-ggplot(data=s1SigData, mapping = aes(x=s1, y=s2))+geom_point()+
scale_y_continuous(breaks=seq(-8, 8, 1), limits=c(-8,8))+scale_x_continuous(breaks=seq(-8, 8, 1), limits=c(-8, 8))
s1Sigs2
#calculating s2 given s1
calculate_pcondtional<-function(s1){
mean<-(sigma_g^2*s1)/(1+sigma_g^2+sigma_c1^2)
var<-(1-(sigma_g^4)/((1+sigma_g^2+sigma_c1^2)*(1+sigma_g^2+sigma_c2^2)))*(1+sigma_g^2+sigma_c2^2)
p<- (1-pnorm(5.2, mean, sqrt(var)))+pnorm(-5.2, mean, sqrt(var))
return(p)
}
#estimating sigma g from having two confounders
#variance of (s1+s2)-(s1-s2)
# sigma_g_est=(var(data$s1+data$s2)-var(data$s1-data$s2))*(1/4)
# var_c1_est=var(data$s1)-1-sigma_g_est
# var_c2_est=var(data$s2)-1-sigma_g_est
MLE<-function(var){
#estimate<-choose(M,num_s1)
for(i in s1_sig$s1){
estimate<-estimate*dnorm(i, mean=0, sd=sqrt(var))
}
estimate<-estimate*(pnorm(ZScore*sqrt(N_1), mean=0, sd=sqrt(var)))^(M-num_s1)
}
max<-0
maxVar<-0
for(i in seq(from=0.1, to=1000, by=.1)){
temp<-MLE(i)
#print(temp)
if (temp>max) {
max<-temp
maxVar<-i
}
}
#libraries
library(tidyverse)
library(MASS)
library(ggplot2)
library(dplyr)
library(plyr)
library(reshape2)
#simulating data
var_g<-4*.75
var_c1<-4*.25
var_c2<-4*.25
sigma<-sqrt(var_g)
sigma_c1<-sqrt(var_c1) #first study
sigma_c2<-sqrt(var_c2) #second study
M<-1000#number of snps
#pValue<-0.05/M
#pValue<-(1*10^(-4))
ZScore<- qnorm(0.05/M,lower.tail =FALSE)
#ZScore<-5.2
sampleSizeS1<-100
sampleSizeS2<-100
#generating lambda
lambda <- rnorm(n=M, mean=0, sd=sigma)
#generating C1
delta1 <- rnorm(n=M, mean=0, sd=sigma_c1)
#simulating C2
delta2 <- rnorm(n=M, mean=0, sd=sigma_c2)
#generating two test statistics with different confounders
data1<-matrix(nrow=M, ncol=5)
for(i in 1:M){
data1[i,1]<-lambda[i]
data1[i,2]<-delta1[i]
data1[i,3]<-delta2[i]
data1[i,4]<-rnorm(n=1, mean=(lambda[i]+delta1[i])*sqrt(sampleSizeS1), sd=1) #s1
data1[i,5]<-rnorm(n=1, mean=(lambda[i]+delta2[i])*sqrt(sampleSizeS2), sd=1) #s2
}
data1=as.data.frame(data1)
colnames(data1)=c("lambda", "delta1", "delta2", "s1", "s2")
#results.data<-filter(data1, s1>ZScore)
data1$s1_2<-(data1$s1)/sqrt(sampleSizeS1)
data1$s2_2<-(data1$s2)/sqrt(sampleSizeS2)
s1_sig<-data1 %>% filter(s1_2>ZScore | s1_2<(-ZScore))
calculate_upperCI<-function(s1,sampleS1, sampleS2, c1, c2){
sd_S1<-sqrt(sampleS1*sigma^2+1+c1*sampleS1)
sd_S2<-sqrt(sampleS2*sigma^2+1+c2*sampleS2)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-sd_S2^2-((sampleS1*sampleS2*sigma^4)/(sd_S1^2))
error <- qnorm(0.975)*sqrt(var2)
mean+error
}
calculate_lowerCI<-function(s1,sampleS1, sampleS2, c1, c2){
sd_S1<-sqrt(sampleS1*sigma^2+1+c1*sampleS1)
sd_S2<-sqrt(sampleS2*sigma^2+1+c2*sampleS2)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-sd_S2^2-((sampleS1*sampleS2*sigma^4)/(sd_S1^2))
error <- qnorm(0.975)*sqrt(var2)
return(mean-error)
}
calculate_mean<-function(s1,sampleS1,sampleS2, c1, c2){
sd_S1<-sqrt(sampleS1*sigma^2+1+c1*sampleS1)
sd_S2<-sqrt(sampleS2*sigma^2+1+c2*sampleS2)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
}
pred_obs<-ggplot(data = data1, mapping = aes(x = s1, y = s2)) +
geom_point()+
stat_function(fun=calculate_lowerCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=var_c1, c2=var_c2), color="paleturquoise2")+
stat_function(fun=calculate_upperCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=var_c1, c2=var_c2), color="paleturquoise2")+
stat_function(fun=calculate_mean, args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=var_c1, c2=var_c2), color="palevioletred1")
pred_obs
ggsave(filename ="sim_confInterval_confouding.jpg")
pred_obs<-ggplot(data = data1, mapping = aes(x = s1, y = s2)) +
geom_point()+
stat_function(fun=calculate_lowerCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=0, c2=0), color="paleturquoise2")+
stat_function(fun=calculate_upperCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=0, c2=0), color="paleturquoise2")+
stat_function(fun=calculate_mean, args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=0, c2=0), color="palevioletred1")
pred_obs
ggsave(filename ="sim_confInterval_withoutconfouding.jpg")
#estimating confouding and heriability from data
#s1 variance
N_1<-sampleSizeS1
N_2<-sampleSizeS2
num_s1<-sum(data1$s1_2>ZScore)
MLE<-function(var){
#estimate<-choose(M,num_s1)
for(i in s1_sig$s1){
estimate<-estimate*dnorm(i, mean=0, sd=sqrt(var))
}
estimate<-estimate*(pnorm(ZScore*sqrt(N_1), mean=0, sd=sqrt(var)))^(M-num_s1)
}
max<-0
maxVar<-0
for(i in seq(from=0.1, to=1000, by=.1)){
temp<-MLE(i)
#print(temp)
if (temp>max) {
max<-temp
maxVar<-i
}
}
#first method to estimate var_g
expected_mean_ratio<-function(sigma_g_2){
sqrt(N_1*N_2)*sigma_g_2/maxVar
}
sigma_g_estimator <- 0
min_rms <- 10000
var_g_est2 <- 0
for (i in 1:10000){
ratio<-expected_mean_ratio(sigma_g_estimator)
expected_s2 <- s1_sig$s1*ratio
cur_rms <- sqrt(sum((expected_s2-s1_sig$s2)^2))
if (cur_rms < min_rms){
min_rms<- cur_rms
var_g_est2 <- sigma_g_estimator
}
sigma_g_estimator <- sigma_g_estimator+0.001
}
#est c1
c1_est2<-(maxVar-1-var_g_est2*(N_1))/(N_1)
#estimating sigmac2
MLE_joint_probability<-function(var_g, var_c1, var_c2){
cov_matrix=matrix(data=NA, nrow=2, ncol=2)
cov_matrix[1,1]=N_1*var_g+N_1*var_c1+1
cov_matrix[1,2]=sqrt(N_1*N_2)*var_g
cov_matrix[2,1]=sqrt(N_1*N_2)*var_g
cov_matrix[2,2]=N_2*var_g+N_2*var_c2+1
mean_matrix=matrix(data=NA, nrow=2, ncol=1)
mean_matrix[1,1]=0
mean_matrix[2,1]=0
estimate<-choose(M,num_s1)
vector<-(s1_sig[,c(4,5)])
prob<-dmvnorm(x=vector, mean = mean_matrix, sigma = cov_matrix, log = FALSE)
for(i in prob){
estimate<-estimate*i
}
estimate*pnorm(ZScore, mean=0, sd=sqrt(var_g))^(M-num_s1)
}
max<-0
c2_est<-0
for(i in seq(from=0,to=10, by=0.001)){
temp<-MLE_joint_probability(var_g_est2, c1_est2, i)
if(temp>max){
max<-temp
c2_est<-i
}
}
#libraries
library(tidyverse)
library(MASS)
library(ggplot2)
library(dplyr)
library(plyr)
library(reshape2)
#simulating data
var_g<-4*.75
var_c1<-4*.25
var_c2<-4*.25
sigma<-sqrt(var_g)
sigma_c1<-sqrt(var_c1) #first study
sigma_c2<-sqrt(var_c2) #second study
M<-1000#number of snps
#pValue<-0.05/M
#pValue<-(1*10^(-4))
ZScore<- qnorm(0.05/M,lower.tail =FALSE)
#ZScore<-5.2
sampleSizeS1<-100
sampleSizeS2<-100
#generating lambda
lambda <- rnorm(n=M, mean=0, sd=sigma)
#generating C1
delta1 <- rnorm(n=M, mean=0, sd=sigma_c1)
#simulating C2
delta2 <- rnorm(n=M, mean=0, sd=sigma_c2)
#generating two test statistics with different confounders
data1<-matrix(nrow=M, ncol=5)
for(i in 1:M){
data1[i,1]<-lambda[i]
data1[i,2]<-delta1[i]
data1[i,3]<-delta2[i]
data1[i,4]<-rnorm(n=1, mean=(lambda[i]+delta1[i])*sqrt(sampleSizeS1), sd=1) #s1
data1[i,5]<-rnorm(n=1, mean=(lambda[i]+delta2[i])*sqrt(sampleSizeS2), sd=1) #s2
}
data1=as.data.frame(data1)
colnames(data1)=c("lambda", "delta1", "delta2", "s1", "s2")
#results.data<-filter(data1, s1>ZScore)
data1$s1_2<-(data1$s1)/sqrt(sampleSizeS1)
data1$s2_2<-(data1$s2)/sqrt(sampleSizeS2)
s1_sig<-data1 %>% filter(s1_2>ZScore | s1_2<(-ZScore))
calculate_upperCI<-function(s1,sampleS1, sampleS2, c1, c2){
sd_S1<-sqrt(sampleS1*sigma^2+1+c1*sampleS1)
sd_S2<-sqrt(sampleS2*sigma^2+1+c2*sampleS2)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-sd_S2^2-((sampleS1*sampleS2*sigma^4)/(sd_S1^2))
error <- qnorm(0.975)*sqrt(var2)
mean+error
}
calculate_lowerCI<-function(s1,sampleS1, sampleS2, c1, c2){
sd_S1<-sqrt(sampleS1*sigma^2+1+c1*sampleS1)
sd_S2<-sqrt(sampleS2*sigma^2+1+c2*sampleS2)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
var2<-sd_S2^2-((sampleS1*sampleS2*sigma^4)/(sd_S1^2))
error <- qnorm(0.975)*sqrt(var2)
return(mean-error)
}
calculate_mean<-function(s1,sampleS1,sampleS2, c1, c2){
sd_S1<-sqrt(sampleS1*sigma^2+1+c1*sampleS1)
sd_S2<-sqrt(sampleS2*sigma^2+1+c2*sampleS2)
mean<-(sqrt(sampleS1)*sqrt(sampleS2)*sigma^2*s1)/(sd_S1^2)
}
pred_obs<-ggplot(data = data1, mapping = aes(x = s1, y = s2)) +
geom_point()+
stat_function(fun=calculate_lowerCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=var_c1, c2=var_c2), color="paleturquoise2")+
stat_function(fun=calculate_upperCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=var_c1, c2=var_c2), color="paleturquoise2")+
stat_function(fun=calculate_mean, args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=var_c1, c2=var_c2), color="palevioletred1")
pred_obs
ggsave(filename ="sim_confInterval_confouding.jpg")
pred_obs<-ggplot(data = data1, mapping = aes(x = s1, y = s2)) +
geom_point()+
stat_function(fun=calculate_lowerCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=0, c2=0), color="paleturquoise2")+
stat_function(fun=calculate_upperCI,args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=0, c2=0), color="paleturquoise2")+
stat_function(fun=calculate_mean, args=list(sampleS1<-sampleSizeS1, sampleS2<-sampleSizeS2, c1=0, c2=0), color="palevioletred1")
pred_obs
ggsave(filename ="sim_confInterval_withoutconfouding.jpg")
#estimating confouding and heriability from data
#s1 variance
N_1<-sampleSizeS1
N_2<-sampleSizeS2
num_s1<-sum(data1$s1_2>ZScore)
MLE<-function(var){
estimate<-choose(M,num_s1)
for(i in s1_sig$s1){
estimate<-estimate*dnorm(i, mean=0, sd=sqrt(var))
}
estimate<-estimate*(pnorm(ZScore*sqrt(N_1), mean=0, sd=sqrt(var)))^(M-num_s1)
}
max<-0
maxVar<-0
for(i in seq(from=0.1, to=1000, by=.1)){
temp<-MLE(i)
#print(temp)
if (temp>max) {
max<-temp
maxVar<-i
}
}
#first method to estimate var_g
expected_mean_ratio<-function(sigma_g_2){
sqrt(N_1*N_2)*sigma_g_2/maxVar
}
sigma_g_estimator <- 0
min_rms <- 10000
var_g_est2 <- 0
for (i in 1:10000){
ratio<-expected_mean_ratio(sigma_g_estimator)
expected_s2 <- s1_sig$s1*ratio
cur_rms <- sqrt(sum((expected_s2-s1_sig$s2)^2))
if (cur_rms < min_rms){
min_rms<- cur_rms
var_g_est2 <- sigma_g_estimator
}
sigma_g_estimator <- sigma_g_estimator+0.001
}
#est c1
c1_est2<-(maxVar-1-var_g_est2*(N_1))/(N_1)
#estimating sigmac2
MLE_joint_probability<-function(var_g, var_c1, var_c2){
cov_matrix=matrix(data=NA, nrow=2, ncol=2)
cov_matrix[1,1]=N_1*var_g+N_1*var_c1+1
cov_matrix[1,2]=sqrt(N_1*N_2)*var_g
cov_matrix[2,1]=sqrt(N_1*N_2)*var_g
cov_matrix[2,2]=N_2*var_g+N_2*var_c2+1
mean_matrix=matrix(data=NA, nrow=2, ncol=1)
mean_matrix[1,1]=0
mean_matrix[2,1]=0
estimate<-choose(M,num_s1)
vector<-(s1_sig[,c(4,5)])
prob<-dmvnorm(x=vector, mean = mean_matrix, sigma = cov_matrix, log = FALSE)
for(i in prob){
estimate<-estimate*i
}
estimate*pnorm(ZScore, mean=0, sd=sqrt(var_g))^(M-num_s1)
}
max<-0
c2_est<-0
for(i in seq(from=0,to=10, by=0.001)){
temp<-MLE_joint_probability(var_g_est2, c1_est2, i)
if(temp>max){
max<-temp
c2_est<-i
}
}
1+100*var_g+100*var_c1
var(data1$s1)
var(data1 %>% filter(s1>ZSc0re))
var(data1 %>% filter(s1>ZScore))
var(data1$s1 %>% filter(s1>ZScore))
temp<-data1 %>% filter(s1>ZScore)
var(temp$s1)
