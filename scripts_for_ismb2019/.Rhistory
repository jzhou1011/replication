?max
library(ggplot2)
# args = commandArgs(trailingOnly=TRUE)
# filename<-args[1]
# outfile <- args[2]
#
#
# data<-read.table(filename, header=T)
# stopifnot(nrow(data)>1)
#t <- data[1,5]
t <- 0.05/nrow(data)
#simulate data
var_g<-3
var_c1<-1
var_c2<-2
M<-1000
N_1<-2
N_2<-3
lambda<-rnorm(n=M, mean=0, sd=sqrt(var_g))
s1_dist<-as.vector(matrix(nrow=M, ncol=1))
s2_dist<-as.vector(matrix(nrow=M, ncol=1))
delta1<-rnorm(n=M, mean=0, sd=sqrt(var_c1))
delta2<-rnorm(n=M, mean=0, sd=sqrt(var_c2))
for (i in 1:M){
s1_dist[i]<-rnorm(n=1,mean=sqrt(N_1)*(lambda[i]+delta1[i]),sd=1)
s2_dist[i]<-rnorm(n=1,mean=sqrt(N_2)*(lambda[i]+delta2[i]),sd=1)
}
data<-data.frame(s1_dist, s2_dist)
data$N_1<-rep(N_1,M)
data$N_2<-rep(N_2,M)
View(data)
estimate_sigma_g <- function(s1, s2, n1, n2){
D = var(s1 + s2) - var(s1-s2)
return (max((D/(4*sqrt(as.numeric(n1)*as.numeric(n2)))), 0.000000000000000000000000000001) )
}
estimate_sigma_c1 <- function(s1, n1, sigma_g){
num <- var(s1) - as.numeric(n1)*sigma_g - 1
#	return(num/n1)
return(max(num/as.numeric(n1), 0.000000000000000000000000000001))
}
estimate_sigma_c2 <- function(s2, n2, sigma_g){
num <- var(s2) - as.numeric(n2)*sigma_g -1
#	return(num/n2)
return(max(num/as.numeric(n2), 0.000000000000000000000000000001))
}
predict_replication <- function(mean, sd, z){
#calculate predicted replication rate
lower <-  pnorm(z, mean, sd)
upper <- 1- pnorm(-z, mean, sd)
return(lower + upper)
}
predict_no_confounding <- function(data, z){
#currently assume sample size is same for all variants
n1 <- as.numeric(data[1,3])
n2 <- as.numeric(data[1,4])
sigma_g <- estimate_sigma_g(data[,1], data[,2], n1, n2)
#compute mean and standard deviation of conditional distribution
mean <- data[,1] * (sqrt(n1*n2) *sigma_g)/(n1*sigma_g + 1) #vector
sd <- sqrt(1 + (n2*sigma_g)/(n1*sigma_g +1))	#scalar
slope <- (sqrt(n1*n2) *sigma_g)/(n1*sigma_g + 1)
#calculate replication rate across significant SNPs in initial study
predicted_replication <- 0
for(i in 1:nrow(data)){
predicted_replication <- predicted_replication +  predict_replication(mean[i], sd, z)
}
return(c(predicted_replication/nrow(data), sigma_g, slope, sd))
}
predict_with_confounding <- function(data, z){
n1 <- as.numeric(data[1,3])
n2 <- as.numeric(data[1,4])
sigma_g <- estimate_sigma_g(data[,1], data[,2], n1, n2)
sigma_c1 <- estimate_sigma_c1(data[,1], n1, sigma_g)
sigma_c2 <- estimate_sigma_c2(data[,2], n2, sigma_g)
#calculate mean and sd of conditional distribution
mean <- data[,1]* (sqrt(n1*n2) *sigma_g) / (n1*sigma_g + n1*sigma_c1 +1) #vector
sd <- sqrt(n2*sigma_g + n2*sigma_c2 + 1 - (n1*n2*sigma_g*sigma_g)/(n1*sigma_g + n1*sigma_c1 +1)) #scalar
slope <- (sqrt(n1*n2) *sigma_g) / (n1*sigma_g + n1*sigma_c1 +1)
#calculate replication rate across significant SNPs in initial study
predicted_replication <- 0
for(i in 1:nrow(data)){
predicted_replication <- predicted_replication +  predict_replication(mean[i], sd, z)
}
return(c(predicted_replication/nrow(data), sigma_g, sigma_c1, sigma_c2, slope, sd))
}
calcReplication <- function(data, z){
count <- 0
for(i in 1:nrow(data)){
if(abs(data[i,2])>abs(z)){
count  <- count + 1
}
}
return(c(count/nrow(data), count))
}
z <- qnorm(t/2)
r_true <- calcReplication(data, z)
t <- 0.05/nrow(data)
#z-score for lower significance bound (upper bound is -1*lower bound)
#need to adjust by factor of 1/2 for two sided test
z <- qnorm(t/2)
#true replication rate
r_true <- calcReplication(data, z)
pr_no_confounding <- predict_no_confounding(data, z)
count_no_confounding <- round(pr_no_confounding[1]*nrow(data))
#predicted replicatino rate with confounding
pr_with_confounding <- predict_with_confounding(data, z)
count_with_confounding <- round(pr_with_confounding[1]*nrow(data))
pr_no_confounding
pr_with_confounding
calcReplication <- function(data, z){
count <- 0
for(i in 1:nrow(data)){
if(abs(data[i,2])>abs(z)){
count  <- count + 1
}
}
return(c(count/nrow(data), count))
}
#true replication rate
r_true <- calcReplication(data, z)
